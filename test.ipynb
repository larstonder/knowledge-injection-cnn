{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 50,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Test mode\n",
      "Directory already exists\n",
      "Directory already exists\n"
     ]
    }
   ],
   "source": [
    "# Author: Mattia Silvestri\n",
    "\n",
    "\"\"\"\n",
    "Main program.\n",
    "\"\"\"\n",
    "\n",
    "import os\n",
    "\n",
    "os.environ[\"TF_CPP_MIN_LOG_LEVEL\"] = \"3\"\n",
    "from utility import PLSInstance, PLSSolver, random_assigner\n",
    "from models import MyModel\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import tensorflow as tf\n",
    "import csv\n",
    "import argparse\n",
    "import time\n",
    "import pandas as pd\n",
    "\n",
    "########################################################################################################################\n",
    "\n",
    "# Set seed in order to reproduce results\n",
    "tf.random.set_seed(0)\n",
    "\n",
    "# Tensorflow 2 GPU setup\n",
    "gpus = tf.config.experimental.list_physical_devices('GPU')\n",
    "if gpus:\n",
    "    # Restrict TensorFlow to only use the first GPU\n",
    "    try:\n",
    "        tf.config.experimental.set_visible_devices(gpus[0], 'GPU')\n",
    "        tf.config.experimental.set_virtual_device_configuration(\n",
    "            gpus[0],\n",
    "            [tf.config.experimental.VirtualDeviceConfiguration(memory_limit=8192)])\n",
    "        logical_gpus = tf.config.experimental.list_logical_devices('GPU')\n",
    "        print(len(gpus), \"Physical GPUs,\", len(logical_gpus), \"Logical GPU\")\n",
    "    except RuntimeError as e:\n",
    "        # Visible devices must be set before GPUs have been initialized\n",
    "        print(e)\n",
    "\n",
    "########################################################################################################################\n",
    "\n",
    "parser = argparse.ArgumentParser()\n",
    "parser.add_argument(\"--dim\", type=int, default=10, help=\"Problem dimension\")\n",
    "parser.add_argument(\"--train\", action=\"store_true\",\n",
    "                    help=\"Train the model; if not set the default is test mode.\", default=False)\n",
    "parser.add_argument(\"--test-num\", default=None,\n",
    "                    help=\"Test identifier.\")\n",
    "parser.add_argument(\"--num-epochs\", default=300, type=int,\n",
    "                    help=\"Number of training epochs.\")\n",
    "parser.add_argument(\"--max-size\", default=1000000, type=int,\n",
    "                    help=\"Maximum number of training/test instances to be loaded.\")\n",
    "parser.add_argument(\"--load-mode\", default=\"onehot\", choices=[\"onehot\", \"string\"],\n",
    "                    help=\"Dataset loading mode.\")\n",
    "parser.add_argument(\"--batch-size\", default=1024, type=int,\n",
    "                    help=\"Mini-batch size.\")\n",
    "parser.add_argument(\"--leave-columns-domains\", action=\"store_true\", default=False,\n",
    "                    help=\"True if you don't want to prune columns domains values with forward checking.\")\n",
    "parser.add_argument(\"--num-sol\", type=str, default=\"10k\",\n",
    "                    help=\"Number of solutions from which the training set has been generated; thousands are expressed \"\n",
    "                         + \"with k (for example 10000=10k).\")\n",
    "parser.add_argument(\"--model\", default=\"fnn\", choices=[\"fnn\", \"cnn\"],\n",
    "                    help=\"Choose the model architecture.\")  # TODO: change default\n",
    "parser.add_argument(\"--model-type\", default=\"agnostic\", choices=[\"agnostic\", \"sbrinspiredloss\", \"negative\", \"binary\"],\n",
    "                    help=\"Choose the model type. 'agnostic' is the model-agnostic baseline. 'sbrinspiredloss', \"\n",
    "                         + \"'negative' and 'binary' are relatively the mse, negative and binary-cross entropy versions\"\n",
    "                         + \" of the SBR inspiredloss.\")\n",
    "parser.add_argument(\"--validation-size\", type=int, default=0,\n",
    "                    help=\"Validation set dimension. If zero no validation set is used.\")\n",
    "parser.add_argument(\"--use-prop\", action=\"store_true\", default=False,\n",
    "                    help=\"True if you want to assist the estimators with constraints propagation at evaluation time.\")\n",
    "parser.add_argument(\"--rnd-feas\", action=\"store_true\", default=False,\n",
    "                    help=\"True if you want to compute feasibility ratio also for random estimator.\")\n",
    "parser.add_argument(\"--lmbd\", default=1.0, type=float, help=\"Lambda for SBR-inspired term.\")\n",
    "parser.add_argument(\"--patience\", default=10, type=int,\n",
    "                    help=\"Specify the number of 10 epochs intervals without improvement in \"\n",
    "                         \"feasibility after which training is stopped.\")\n",
    "\n",
    "# args = parser.parse_args()\n",
    "args = parser.parse_args([\"--dim\", \"7\", \"--test-num\", \"pls-7/cnn/all-ts/run-1\", \"--num-epochs\", \"10000\", \"--max-size\", \"1000000\", \"--batch-size\", \"2048\", \"--num-sol\", \"10k\", \"--model\", \"cnn\", \"--model-type\", \"agnostic\", \"--validation-size\", \"5000\", \"--patience\", \"10\"])  # \"--train\",\n",
    "\n",
    "# Problem dimension.\n",
    "DIM = int(args.dim)\n",
    "\n",
    "COLUMN_TYPES = [int() for _ in range(DIM ** 3)]\n",
    "\n",
    "# Set training or test mode.\n",
    "TRAIN = args.train\n",
    "if TRAIN:\n",
    "    print(\"Training mode\")\n",
    "    mode = \"train\"\n",
    "else:\n",
    "    print(\"Test mode\")\n",
    "    mode = \"test\"\n",
    "\n",
    "# Test number identifier\n",
    "TEST_NUM = args.test_num\n",
    "\n",
    "# Number of training epochs\n",
    "EPOCHS = int(args.num_epochs)\n",
    "\n",
    "# Maximum number of data set examples to load\n",
    "MAX_SIZE = int(args.max_size)\n",
    "\n",
    "# Available loading mode are string and one-hot\n",
    "LOAD_MODE = args.load_mode\n",
    "\n",
    "# Mini-batch size\n",
    "BATCH_SIZE = int(args.batch_size)\n",
    "\n",
    "# True if you want to adopt SRB-inspired loss function\n",
    "MODEL_TYPE = args.model_type\n",
    "\n",
    "if mode == \"test\":\n",
    "    mode_char = \"L\"\n",
    "else:\n",
    "    mode_char = \"B\"\n",
    "\n",
    "if not TRAIN:\n",
    "    file_name = \"pls{}_10k\".format(DIM)\n",
    "else:\n",
    "    file_name = \"pls{}_{}\".format(DIM, args.num_sol)\n",
    "\n",
    "VAL_SIZE = args.validation_size\n",
    "\n",
    "NUM_SOL = args.num_sol\n",
    "\n",
    "# Model name for both training and test\n",
    "model_name = \"test-{}/\".format(TEST_NUM)\n",
    "\n",
    "# Where to save plots\n",
    "SAVE_PATH = \"plots/test-{}/\".format(TEST_NUM)\n",
    "try:\n",
    "    os.makedirs(SAVE_PATH)\n",
    "except:\n",
    "    print(\"Directory already exists\")\n",
    "\n",
    "# Model name for both training and test\n",
    "model_name = \"test-{}/\".format(TEST_NUM)\n",
    "\n",
    "# Where to save plots\n",
    "SAVE_PATH = \"plots/test-{}/\".format(TEST_NUM)\n",
    "try:\n",
    "    os.makedirs(SAVE_PATH)\n",
    "except:\n",
    "    print(\"Directory already exists\")\n",
    "\n",
    "########################################################################################################################"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loading validation set...\n",
      "Elapsed 17.54376459121704 seconds\n",
      "Loading features from datasets/pls7/partial_solutions_10k_train.csv...\n",
      "Elapsed 19.937610626220703 seconds, 0.122217074 GB required\n",
      "Number of rows: 356318\n",
      "Loading labels from datasets/pls7/assignments_10k_train.csv...\n",
      "Elapsed 0.28601932525634766 seconds, 0.001425272 GB required\n",
      "Elapsed 0.3430154323577881 seconds, 0.122217074 GB required\n"
     ]
    }
   ],
   "source": [
    "# Create a validation set if required\n",
    "val_indexes = None\n",
    "\n",
    "if VAL_SIZE > 0:\n",
    "    print(\"Loading validation set...\")\n",
    "    start = time.time()\n",
    "    X_val = pd.read_csv(\"datasets/pls{}/partial_solutions_{}_train.csv\".format(DIM, NUM_SOL),\n",
    "                        sep=',',\n",
    "                        header=None,\n",
    "                        nrows=MAX_SIZE,\n",
    "                        dtype=np.int8).values\n",
    "\n",
    "    # Create penalties for the examples\n",
    "    if MODEL_TYPE != 'agnostic':\n",
    "        P_val = pd.read_csv(\"datasets/pls{}/domains_train_{}.csv\".format(DIM, NUM_SOL),\n",
    "                            sep=',',\n",
    "                            header=None,\n",
    "                            nrows=MAX_SIZE,\n",
    "                            dtype=np.int8).values\n",
    "    else:\n",
    "        P_val = np.zeros_like(X_val, dtype=np.int8)\n",
    "\n",
    "    end = time.time()\n",
    "    print(\"Elapsed {} seconds\".format((end - start)))\n",
    "\n",
    "    val_indexes = np.random.choice(np.arange(0, X_val.shape[0]), size=VAL_SIZE, replace=False)\n",
    "    X_val = X_val[val_indexes]\n",
    "    P_val = P_val[val_indexes]\n",
    "    validation_set = (X_val, P_val)\n",
    "\n",
    "# Load training examples\n",
    "features_filepath = \"datasets/pls{}/partial_solutions_{}_{}.csv\".format(DIM, NUM_SOL, mode)\n",
    "print(\"Loading features from {}...\".format(features_filepath))\n",
    "start = time.time()\n",
    "X = pd.read_csv(features_filepath, sep=',', header=None, nrows=MAX_SIZE, dtype=np.int8).values\n",
    "end = time.time()\n",
    "print(\"Elapsed {} seconds, {} GB required\".format((end - start), X.nbytes / 10 ** 9))\n",
    "print(\"Number of rows: {}\".format(X.shape[0]))\n",
    "\n",
    "labels_filepath = \"datasets/pls{}/assignments_{}_{}.csv\".format(DIM, NUM_SOL, mode)\n",
    "print(\"Loading labels from {}...\".format(labels_filepath))\n",
    "start = time.time()\n",
    "Y = pd.read_csv(labels_filepath, sep=',', header=None, nrows=MAX_SIZE, dtype=np.int32).values\n",
    "end = time.time()\n",
    "print(\"Elapsed {} seconds, {} GB required\".format((end - start), Y.nbytes / 10 ** 9))\n",
    "\n",
    "# Create penalties for the examples\n",
    "if MODEL_TYPE == 'agnostic' and not args.use_prop:\n",
    "    P = np.zeros_like(X, dtype=np.int8)\n",
    "else:\n",
    "    if not args.leave_columns_domains:\n",
    "        penalties_filepath = \"datasets/pls{}/domains_{}_{}.csv\".format(DIM, mode, NUM_SOL)\n",
    "    else:\n",
    "        penalties_filepath = \"datasets/pls{}/rows_propagation_domains_{}_{}.csv\".format(DIM, mode, NUM_SOL)\n",
    "\n",
    "    print(\"Loading penalties from {}...\".format(penalties_filepath))\n",
    "    start = time.time()\n",
    "    P = pd.read_csv(penalties_filepath, sep=',', header=None, nrows=MAX_SIZE, dtype=np.int8).values\n",
    "end = time.time()\n",
    "print(\"Elapsed {} seconds, {} GB required\".format((end - start), P.nbytes / 10 ** 9))\n",
    "\n",
    "# Remove validation samples from the training set\n",
    "if val_indexes is not None:\n",
    "    X = np.delete(X, val_indexes, axis=0)\n",
    "    Y = np.delete(Y, val_indexes, axis=0)\n",
    "    P = np.delete(P, val_indexes, axis=0)\n"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "outputs": [],
   "source": [
    "# Create TF datasets\n",
    "dataset = tf.data.Dataset.from_tensor_slices((X, Y, P)).shuffle(10000).batch(BATCH_SIZE)"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "outputs": [],
   "source": [
    "####### MODEL DEFINITION - models.py\n",
    "\n",
    "import tensorflow as tf\n",
    "from tensorflow.keras.layers import Conv2D, MaxPooling2D, Flatten, Dense, BatchNormalization, Activation, Reshape\n",
    "from tensorflow.keras import layers\n",
    "from tensorflow.keras.utils import plot_model\n",
    "\n",
    "\n",
    "class PLSCNNModel(MyModel):\n",
    "    def _define_model(self, input_shape):\n",
    "        model = tf.keras.Sequential()\n",
    "        model.add(Reshape((7, 7, 7), input_shape=(7**3,)))\n",
    "\n",
    "        model.add(Conv2D(32, kernel_size=(7, 1), activation='relu', padding='same'))\n",
    "        model.add(Conv2D(32, kernel_size=(1, 7), activation='relu', padding='same'))\n",
    "        # model.add(MaxPooling2D((2, 2)))\n",
    "        model.add(BatchNormalization())\n",
    "\n",
    "        model.add(Conv2D(64, (3, 1), activation='relu', padding='same'))\n",
    "        model.add(Conv2D(64, (1, 3), activation='relu', padding='same'))\n",
    "        # model.add(MaxPooling2D((2, 2)))\n",
    "        model.add(BatchNormalization())\n",
    "\n",
    "        # model.add(Conv2D(128, (1, 1), activation='relu', padding='same'))\n",
    "        # model.add(BatchNormalization())\n",
    "\n",
    "        model.add(Flatten())\n",
    "        model.add(Dense(64, activation='relu'))\n",
    "        model.add(Dense(7**3))  # Loss function expects logits\n",
    "\n",
    "        self.model = model\n",
    "\n",
    "    def call(self, inputs):\n",
    "        return self.model(inputs)"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "outputs": [],
   "source": [
    "# Create the model\n",
    "if args.model == \"cnn\":\n",
    "    model = PLSCNNModel(num_layers=3,\n",
    "                        num_hidden=[],\n",
    "                        input_shape=X.shape[1:],\n",
    "                        output_dim=DIM ** 3,\n",
    "                        method=MODEL_TYPE, # \"agnostic\", \"sbrinspiredloss\", \"negative\", \"binary\"\n",
    "                        lmbd=args.lmbd)\n",
    "else:\n",
    "    model = MyModel(num_layers=2,\n",
    "                    num_hidden=[512, 512],\n",
    "                    input_shape=X.shape[1:],\n",
    "                    output_dim=DIM ** 3,\n",
    "                    method=MODEL_TYPE,\n",
    "                    lmbd=args.lmbd)\n"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"sequential_6\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "reshape_8 (Reshape)          (None, 7, 7, 7)           0         \n",
      "_________________________________________________________________\n",
      "conv2d_18 (Conv2D)           (None, 7, 7, 32)          1600      \n",
      "_________________________________________________________________\n",
      "conv2d_19 (Conv2D)           (None, 7, 7, 32)          7200      \n",
      "_________________________________________________________________\n",
      "batch_normalization_40 (Batc (None, 7, 7, 32)          128       \n",
      "_________________________________________________________________\n",
      "conv2d_20 (Conv2D)           (None, 7, 7, 64)          6208      \n",
      "_________________________________________________________________\n",
      "conv2d_21 (Conv2D)           (None, 7, 7, 64)          12352     \n",
      "_________________________________________________________________\n",
      "batch_normalization_41 (Batc (None, 7, 7, 64)          256       \n",
      "_________________________________________________________________\n",
      "flatten_6 (Flatten)          (None, 3136)              0         \n",
      "_________________________________________________________________\n",
      "dense_12 (Dense)             (None, 64)                200768    \n",
      "_________________________________________________________________\n",
      "dense_13 (Dense)             (None, 343)               22295     \n",
      "=================================================================\n",
      "Total params: 250,807\n",
      "Trainable params: 250,615\n",
      "Non-trainable params: 192\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "model.model.summary()"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:5 out of the last 5 calls to <function Model.make_predict_function.<locals>.predict_function at 0x0000020F3B5C4F78> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/tutorials/customization/performance#python_or_tensor_args and https://www.tensorflow.org/api_docs/python/tf/function for  more details.\n"
     ]
    },
    {
     "data": {
      "text/plain": "array([[-4.73650359e-03, -2.01584622e-02,  2.09986954e-03,\n         7.17998110e-03,  1.18609499e-02, -5.47342375e-03,\n        -6.72534760e-03, -7.34255556e-03, -1.48158185e-02,\n        -1.63298603e-02,  9.69978422e-03,  1.25913043e-02,\n        -1.03253992e-02, -1.75762437e-02, -1.87293813e-02,\n         1.19368145e-02, -1.63152465e-03, -9.23205726e-03,\n         4.74093156e-03,  6.68801554e-03, -1.32867601e-02,\n        -9.90432035e-03,  1.04816537e-02, -1.34730088e-02,\n        -1.34357205e-03,  6.54482655e-03,  4.57880180e-03,\n         6.49451651e-03, -4.47922666e-03,  3.14505259e-03,\n         7.75613589e-03, -1.85543555e-03,  1.82329789e-02,\n         1.48885222e-02,  9.70343780e-03,  1.10105600e-03,\n        -7.22034089e-03, -6.86610863e-03, -1.36830984e-02,\n         1.24950772e-02,  1.29224639e-02, -3.75703466e-03,\n         1.62678063e-02,  4.24929056e-03, -9.35606472e-03,\n        -8.69772490e-03, -1.72871840e-03,  1.28156980e-02,\n         9.83717944e-03,  1.12139643e-03, -3.83308018e-03,\n         1.10448319e-02,  1.30237853e-02,  3.61985480e-03,\n         5.38043957e-03, -7.76532292e-03,  1.27955806e-02,\n        -5.86825004e-03,  1.96538866e-04, -1.42780021e-02,\n         2.67985985e-02, -4.29333095e-03,  4.81979921e-03,\n        -1.14739081e-02, -1.93336811e-02,  8.48820526e-03,\n         6.10217080e-03,  7.05062179e-04,  1.45479059e-02,\n         1.29132476e-02,  1.50885545e-02, -9.06138495e-03,\n         1.23989088e-02,  1.11618172e-03, -8.42866022e-03,\n        -4.64443862e-03,  3.21649876e-03,  3.42166657e-03,\n        -1.00801243e-02,  1.09749325e-02, -2.17479514e-03,\n        -2.03896649e-02, -5.75527176e-03, -2.75922902e-02,\n        -1.50653441e-03, -1.69749632e-02,  1.01292785e-02,\n        -1.19113084e-02, -1.00419922e-02, -6.07253518e-03,\n        -7.24618090e-03, -3.67784407e-04, -1.41521422e-02,\n        -1.24173937e-02, -9.64205805e-03, -1.98510103e-02,\n         1.07959169e-03,  2.52670310e-02, -2.41408572e-02,\n        -1.45452023e-02,  8.94323550e-03,  7.70559488e-03,\n        -1.28724780e-02, -1.84342805e-02, -1.43767074e-02,\n         4.90495935e-03,  9.54631832e-05,  1.08454041e-02,\n        -8.16307683e-03,  1.05087487e-02,  1.08170314e-02,\n        -1.31194042e-02, -8.71442631e-03,  1.60316471e-04,\n        -3.53252515e-03,  9.97235719e-03, -1.06319785e-02,\n        -7.43671646e-03, -9.13465163e-04, -1.16027836e-02,\n        -1.14792772e-03, -1.37966797e-02,  5.74656809e-03,\n        -5.84864384e-03, -1.99625175e-02,  1.58467758e-02,\n        -5.67174796e-03,  5.87073434e-03,  1.62769035e-02,\n         7.61076808e-03,  2.55769584e-03, -1.99613161e-03,\n        -3.16551188e-03, -4.81891632e-03, -1.48474872e-02,\n        -4.57059685e-03,  4.42405278e-03, -2.73634028e-03,\n         1.67492013e-02, -1.14953483e-03, -3.89492651e-03,\n         8.65128636e-03, -9.55307297e-03,  1.94766745e-02,\n         1.62678584e-02,  1.30863511e-03,  3.66411870e-03,\n        -2.51209503e-03,  1.70014091e-02,  5.09709353e-03,\n         3.57796764e-03, -1.34616054e-03, -6.53504021e-03,\n        -6.69089053e-03, -1.80772524e-02,  6.10591844e-03,\n         7.68799009e-03,  9.42519691e-04,  2.09786394e-03,\n         9.92399827e-03,  4.94471658e-03, -1.16330874e-03,\n        -6.48736954e-03,  5.49667981e-03,  2.70210998e-03,\n        -1.12932245e-03, -2.75407149e-03, -6.12871815e-03,\n         5.18938107e-03,  2.70023569e-02, -7.52324983e-03,\n         1.01053789e-02,  6.46751840e-03,  2.10657977e-02,\n         1.20194338e-03, -5.87560423e-03,  1.23514123e-02,\n         6.29081405e-05,  1.63676552e-02,  1.88582274e-03,\n        -7.20933825e-03,  4.63454518e-04,  2.04408523e-02,\n         4.99232672e-03, -1.33296847e-03,  1.40314670e-02,\n        -5.33926161e-03, -1.23440311e-03, -6.01437548e-03,\n         4.62982338e-03, -3.77455517e-03, -1.44888507e-02,\n         1.90668143e-02, -4.43255203e-03,  4.41576494e-03,\n         9.20723565e-03,  3.49663338e-03,  7.34477211e-03,\n        -5.79879899e-03, -2.99983472e-03,  1.65157374e-02,\n        -2.05529872e-02, -1.54212827e-03,  3.08903842e-03,\n         1.19885048e-02, -8.53975210e-03, -2.30687438e-03,\n        -4.59220260e-03, -8.88189068e-04,  5.53387171e-03,\n        -2.19565015e-02, -7.55114155e-03, -1.37729920e-04,\n        -1.23865781e-02, -8.61547887e-04, -3.00184125e-04,\n         6.27648830e-03,  1.00565711e-02,  3.02299559e-02,\n        -3.81963677e-03,  1.43146073e-03,  2.83074332e-03,\n        -1.27565470e-02, -1.48181869e-02, -2.21843878e-03,\n         7.17023481e-03, -7.99535215e-03,  5.59314992e-03,\n        -2.30395589e-02,  1.39664747e-02, -1.39002064e-02,\n         2.83062016e-03,  4.66109533e-03,  1.61196142e-02,\n         1.21103823e-02, -7.60229479e-04,  5.68095967e-03,\n        -6.28742576e-03,  2.15590419e-03, -2.23012529e-02,\n        -2.59308796e-03,  2.16765497e-02, -2.83008050e-02,\n        -1.10968985e-02, -1.10994717e-02, -1.06505649e-02,\n         1.08551253e-02,  5.31991990e-03, -5.86621882e-03,\n         1.49480896e-02,  1.98141974e-03,  1.28655620e-02,\n        -1.40555017e-02, -1.18179834e-02, -2.14064382e-02,\n         3.92809464e-03,  8.92967917e-03, -1.46259330e-02,\n         2.21473165e-02,  8.34678113e-03,  4.10344498e-03,\n         2.41987631e-02, -7.00844452e-03, -1.88087914e-02,\n        -8.04242957e-03, -1.74913742e-02,  3.57146841e-03,\n         3.13170394e-03,  6.94683986e-03, -1.60290934e-02,\n        -8.31898581e-03, -6.96382299e-03,  7.24954437e-03,\n        -3.10348626e-02,  7.84641504e-03,  8.04555777e-04,\n         1.69280414e-02,  2.22838316e-02, -2.49439105e-03,\n        -6.89105550e-03,  2.22775564e-02, -8.10426287e-03,\n        -2.51870528e-02,  1.20156500e-02, -2.32281303e-03,\n         9.24632885e-03, -3.24848341e-04,  7.21345656e-04,\n         3.67916748e-02, -9.16046929e-03, -3.59620550e-03,\n         1.82980094e-02, -9.20067634e-03,  1.87805705e-02,\n        -2.36648531e-03,  8.16314248e-04,  1.13040470e-02,\n        -1.70527305e-03, -1.09902220e-02, -7.15071894e-03,\n         4.59493836e-03,  1.21386843e-02,  1.16774356e-02,\n         8.80434550e-03,  1.50479469e-03, -8.01818259e-03,\n        -6.54811785e-03,  1.14518814e-02, -8.76491051e-03,\n         1.82712320e-02, -6.43698918e-03,  9.60706919e-03,\n        -1.46607892e-03,  2.12893859e-02, -2.58661225e-03,\n        -4.82718041e-03, -1.28617452e-03,  1.81950955e-03,\n         5.64709585e-03, -6.70836959e-03, -7.06352934e-04,\n        -5.37211820e-03,  3.83046526e-03, -1.18268374e-02,\n         6.87658694e-03, -5.43720508e-03,  1.67719387e-02,\n         2.17149388e-02, -1.67554021e-02,  2.03814358e-03,\n        -3.83470673e-03,  2.80980370e-03, -7.15942727e-03,\n         3.41372099e-03,  4.42036660e-04, -1.78771431e-03,\n        -2.94120167e-03, -7.97566865e-03,  1.04586128e-02,\n        -5.64705627e-03,  3.34831863e-03, -1.20707992e-02,\n        -1.33173075e-02]], dtype=float32)"
     },
     "execution_count": 47,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.predict(X[:1].astype(float))"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "outputs": [],
   "source": [
    "# Train model\n",
    "if TRAIN:\n",
    "    history = model.train(EPOCHS,\n",
    "                          dataset,\n",
    "                          \"models/{}\".format(model_name) + str(np.random.randint(1, 10000)),\n",
    "                          DIM,\n",
    "                          validation_set,\n",
    "                          args.use_prop,\n",
    "                          args.patience)\n",
    "\n",
    "    for name in history.keys():\n",
    "        values = history[name]\n",
    "\n",
    "        plt.plot(np.arange(0, len(values)), values,\n",
    "                 label=name)\n",
    "        plt.ylim(bottom=0)\n",
    "        plt.legend()\n",
    "        plt.savefig(\"{}/{}.png\".format(SAVE_PATH, name))\n",
    "        plt.close()\n",
    "\n",
    "        with open(\"{}/{}.csv\".format(SAVE_PATH, name), \"w\") as file:\n",
    "            wr = csv.writer(file)\n",
    "            wr.writerow(values)\n",
    "            file.close()\n",
    "    exit(0)\n",
    "\n",
    "else:\n",
    "    model.model = tf.saved_model.load(\"models/{}\".format(model_name))\n"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 68,
   "outputs": [],
   "source": [
    "X_tensor = X.astype(np.float32)\n",
    "X_tensor = tf.convert_to_tensor(X_tensor, dtype=tf.float32)\n",
    "\n",
    "infer = model.model.signatures[\"serving_default\"]\n",
    "# Make inference\n",
    "pred_tensor = infer(X_tensor)\n"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 69,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'dense_3': <tf.Tensor: shape=(351318, 343), dtype=float32, numpy=\n",
      "array([[-2.5986722 , -1.6797662 , -1.0459328 , ..., -1.218635  ,\n",
      "        -0.10315448, -1.6703275 ],\n",
      "       [-3.6340992 , -2.3993962 , -1.6982248 , ..., -1.1122572 ,\n",
      "         0.04810607, -1.272087  ],\n",
      "       [-3.2417114 , -2.3754346 , -1.9868344 , ..., -0.79298204,\n",
      "         0.15775168, -0.93916833],\n",
      "       ...,\n",
      "       [-0.0761533 ,  0.07599507,  0.01654844, ..., -0.16565886,\n",
      "        -0.08524382, -0.21267867],\n",
      "       [-0.10730623,  0.02281542, -0.04375248, ..., -0.0653744 ,\n",
      "        -0.05370036, -0.13454117],\n",
      "       [-0.02866615,  0.03528141, -0.02712772, ..., -0.09784694,\n",
      "        -0.07933479, -0.17733492]], dtype=float32)>}\n"
     ]
    }
   ],
   "source": [
    "print(pred_tensor)"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "markdown",
   "source": [],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%% md\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 70,
   "outputs": [],
   "source": [
    "\n",
    "# Inference output is a dictionary; last layer is the output one\n",
    "pred_tensor = pred_tensor[\"dense_{}\".format(model.num_layers)]"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 71,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<tensorflow.python.saved_model.load.Loader._recreate_base_user_object.<locals>._UserObject object at 0x0000020F00BC0708>\n"
     ]
    }
   ],
   "source": [
    "################################################################################\n",
    "\n",
    "# Test the model\n",
    "\n",
    "# Make predictions\n",
    "tensor_X = X.astype(np.float32)\n",
    "predict_val = model.predict_from_saved_model(tensor_X).numpy()\n",
    "\n",
    "# Prune values according to constraints propagator if required\n",
    "if args.use_prop:\n",
    "    predict_val *= (1 - P)\n",
    "\n",
    "# Count of correct predictions grouped by number of assigned variables\n",
    "pred_by_num_assigned = np.zeros(shape=(DIM ** 2))\n",
    "# Count of feasible solutions grouped by number of assigned variables\n",
    "feas_by_num_assigned = np.zeros(shape=(DIM ** 2))\n",
    "# Count of total examples grouped by number of assigned variables\n",
    "tot_by_num_assigned = np.zeros(shape=(DIM ** 2))\n",
    "# Count of random correct predictions grouped by number of assigned variables\n",
    "rand_pred_by_num_assigned = np.zeros(shape=(DIM ** 2))\n",
    "# Count of random feasible solutions grouped by number of assigned variables\n",
    "rand_feas_by_num_assigned = np.zeros(shape=(DIM ** 2))\n"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 72,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Examined 0 instances\n",
      "Examined 1000 instances\n",
      "Examined 2000 instances\n",
      "Examined 3000 instances\n",
      "Examined 4000 instances\n",
      "Examined 5000 instances\n",
      "Examined 6000 instances\n",
      "Examined 7000 instances\n",
      "Examined 8000 instances\n",
      "Examined 9000 instances\n",
      "Examined 10000 instances\n",
      "Examined 11000 instances\n",
      "Examined 12000 instances\n",
      "Examined 13000 instances\n",
      "Examined 14000 instances\n",
      "Examined 15000 instances\n",
      "Examined 16000 instances\n",
      "Examined 17000 instances\n",
      "Examined 18000 instances\n",
      "Examined 19000 instances\n",
      "Examined 20000 instances\n",
      "Examined 21000 instances\n",
      "Examined 22000 instances\n",
      "Examined 23000 instances\n",
      "Examined 24000 instances\n",
      "Examined 25000 instances\n",
      "Examined 26000 instances\n",
      "Examined 27000 instances\n",
      "Examined 28000 instances\n",
      "Examined 29000 instances\n",
      "Examined 30000 instances\n",
      "Examined 31000 instances\n",
      "Examined 32000 instances\n",
      "Examined 33000 instances\n",
      "Examined 34000 instances\n",
      "Examined 35000 instances\n",
      "Examined 36000 instances\n",
      "Examined 37000 instances\n",
      "Examined 38000 instances\n",
      "Examined 39000 instances\n",
      "Examined 40000 instances\n",
      "Examined 41000 instances\n",
      "Examined 42000 instances\n",
      "Examined 43000 instances\n",
      "Examined 44000 instances\n",
      "Examined 45000 instances\n",
      "Examined 46000 instances\n",
      "Examined 47000 instances\n",
      "Examined 48000 instances\n",
      "Examined 49000 instances\n",
      "Examined 50000 instances\n",
      "Examined 51000 instances\n",
      "Examined 52000 instances\n",
      "Examined 53000 instances\n",
      "Examined 54000 instances\n",
      "Examined 55000 instances\n",
      "Examined 56000 instances\n",
      "Examined 57000 instances\n",
      "Examined 58000 instances\n",
      "Examined 59000 instances\n",
      "Examined 60000 instances\n",
      "Examined 61000 instances\n",
      "Examined 62000 instances\n",
      "Examined 63000 instances\n",
      "Examined 64000 instances\n",
      "Examined 65000 instances\n",
      "Examined 66000 instances\n",
      "Examined 67000 instances\n",
      "Examined 68000 instances\n",
      "Examined 69000 instances\n",
      "Examined 70000 instances\n",
      "Examined 71000 instances\n",
      "Examined 72000 instances\n",
      "Examined 73000 instances\n",
      "Examined 74000 instances\n",
      "Examined 75000 instances\n",
      "Examined 76000 instances\n",
      "Examined 77000 instances\n",
      "Examined 78000 instances\n",
      "Examined 79000 instances\n",
      "Examined 80000 instances\n",
      "Examined 81000 instances\n",
      "Examined 82000 instances\n",
      "Examined 83000 instances\n",
      "Examined 84000 instances\n",
      "Examined 85000 instances\n",
      "Examined 86000 instances\n",
      "Examined 87000 instances\n",
      "Examined 88000 instances\n",
      "Examined 89000 instances\n",
      "Examined 90000 instances\n",
      "Examined 91000 instances\n",
      "Examined 92000 instances\n",
      "Examined 93000 instances\n",
      "Examined 94000 instances\n",
      "Examined 95000 instances\n",
      "Examined 96000 instances\n",
      "Examined 97000 instances\n",
      "Examined 98000 instances\n",
      "Examined 99000 instances\n",
      "Examined 100000 instances\n",
      "Examined 101000 instances\n",
      "Examined 102000 instances\n",
      "Examined 103000 instances\n",
      "Examined 104000 instances\n",
      "Examined 105000 instances\n",
      "Examined 106000 instances\n",
      "Examined 107000 instances\n",
      "Examined 108000 instances\n",
      "Examined 109000 instances\n",
      "Examined 110000 instances\n",
      "Examined 111000 instances\n",
      "Examined 112000 instances\n",
      "Examined 113000 instances\n",
      "Examined 114000 instances\n",
      "Examined 115000 instances\n",
      "Examined 116000 instances\n",
      "Examined 117000 instances\n",
      "Examined 118000 instances\n",
      "Examined 119000 instances\n",
      "Examined 120000 instances\n",
      "Examined 121000 instances\n",
      "Examined 122000 instances\n",
      "Examined 123000 instances\n",
      "Examined 124000 instances\n",
      "Examined 125000 instances\n",
      "Examined 126000 instances\n",
      "Examined 127000 instances\n",
      "Examined 128000 instances\n",
      "Examined 129000 instances\n",
      "Examined 130000 instances\n",
      "Examined 131000 instances\n",
      "Examined 132000 instances\n",
      "Examined 133000 instances\n",
      "Examined 134000 instances\n",
      "Examined 135000 instances\n",
      "Examined 136000 instances\n",
      "Examined 137000 instances\n",
      "Examined 138000 instances\n",
      "Examined 139000 instances\n",
      "Examined 140000 instances\n",
      "Examined 141000 instances\n",
      "Examined 142000 instances\n",
      "Examined 143000 instances\n",
      "Examined 144000 instances\n",
      "Examined 145000 instances\n",
      "Examined 146000 instances\n",
      "Examined 147000 instances\n",
      "Examined 148000 instances\n",
      "Examined 149000 instances\n",
      "Examined 150000 instances\n",
      "Examined 151000 instances\n",
      "Examined 152000 instances\n",
      "Examined 153000 instances\n",
      "Examined 154000 instances\n",
      "Examined 155000 instances\n",
      "Examined 156000 instances\n",
      "Examined 157000 instances\n",
      "Examined 158000 instances\n",
      "Examined 159000 instances\n",
      "Examined 160000 instances\n",
      "Examined 161000 instances\n",
      "Examined 162000 instances\n",
      "Examined 163000 instances\n",
      "Examined 164000 instances\n",
      "Examined 165000 instances\n",
      "Examined 166000 instances\n",
      "Examined 167000 instances\n",
      "Examined 168000 instances\n",
      "Examined 169000 instances\n",
      "Examined 170000 instances\n",
      "Examined 171000 instances\n",
      "Examined 172000 instances\n",
      "Examined 173000 instances\n",
      "Examined 174000 instances\n",
      "Examined 175000 instances\n",
      "Examined 176000 instances\n",
      "Examined 177000 instances\n",
      "Examined 178000 instances\n",
      "Examined 179000 instances\n",
      "Examined 180000 instances\n",
      "Examined 181000 instances\n",
      "Examined 182000 instances\n",
      "Examined 183000 instances\n",
      "Examined 184000 instances\n",
      "Examined 185000 instances\n",
      "Examined 186000 instances\n",
      "Examined 187000 instances\n",
      "Examined 188000 instances\n",
      "Examined 189000 instances\n",
      "Examined 190000 instances\n",
      "Examined 191000 instances\n",
      "Examined 192000 instances\n",
      "Examined 193000 instances\n",
      "Examined 194000 instances\n",
      "Examined 195000 instances\n",
      "Examined 196000 instances\n",
      "Examined 197000 instances\n",
      "Examined 198000 instances\n",
      "Examined 199000 instances\n",
      "Examined 200000 instances\n",
      "Examined 201000 instances\n",
      "Examined 202000 instances\n",
      "Examined 203000 instances\n",
      "Examined 204000 instances\n",
      "Examined 205000 instances\n",
      "Examined 206000 instances\n",
      "Examined 207000 instances\n",
      "Examined 208000 instances\n",
      "Examined 209000 instances\n",
      "Examined 210000 instances\n",
      "Examined 211000 instances\n",
      "Examined 212000 instances\n",
      "Examined 213000 instances\n",
      "Examined 214000 instances\n",
      "Examined 215000 instances\n",
      "Examined 216000 instances\n",
      "Examined 217000 instances\n",
      "Examined 218000 instances\n",
      "Examined 219000 instances\n",
      "Examined 220000 instances\n",
      "Examined 221000 instances\n",
      "Examined 222000 instances\n",
      "Examined 223000 instances\n",
      "Examined 224000 instances\n",
      "Examined 225000 instances\n",
      "Examined 226000 instances\n",
      "Examined 227000 instances\n",
      "Examined 228000 instances\n",
      "Examined 229000 instances\n",
      "Examined 230000 instances\n",
      "Examined 231000 instances\n",
      "Examined 232000 instances\n",
      "Examined 233000 instances\n",
      "Examined 234000 instances\n",
      "Examined 235000 instances\n",
      "Examined 236000 instances\n",
      "Examined 237000 instances\n",
      "Examined 238000 instances\n",
      "Examined 239000 instances\n",
      "Examined 240000 instances\n",
      "Examined 241000 instances\n",
      "Examined 242000 instances\n",
      "Examined 243000 instances\n",
      "Examined 244000 instances\n",
      "Examined 245000 instances\n",
      "Examined 246000 instances\n",
      "Examined 247000 instances\n",
      "Examined 248000 instances\n",
      "Examined 249000 instances\n",
      "Examined 250000 instances\n",
      "Examined 251000 instances\n",
      "Examined 252000 instances\n",
      "Examined 253000 instances\n",
      "Examined 254000 instances\n",
      "Examined 255000 instances\n",
      "Examined 256000 instances\n",
      "Examined 257000 instances\n",
      "Examined 258000 instances\n",
      "Examined 259000 instances\n",
      "Examined 260000 instances\n",
      "Examined 261000 instances\n",
      "Examined 262000 instances\n",
      "Examined 263000 instances\n",
      "Examined 264000 instances\n",
      "Examined 265000 instances\n",
      "Examined 266000 instances\n",
      "Examined 267000 instances\n",
      "Examined 268000 instances\n",
      "Examined 269000 instances\n",
      "Examined 270000 instances\n",
      "Examined 271000 instances\n",
      "Examined 272000 instances\n",
      "Examined 273000 instances\n",
      "Examined 274000 instances\n",
      "Examined 275000 instances\n",
      "Examined 276000 instances\n",
      "Examined 277000 instances\n",
      "Examined 278000 instances\n",
      "Examined 279000 instances\n",
      "Examined 280000 instances\n",
      "Examined 281000 instances\n",
      "Examined 282000 instances\n",
      "Examined 283000 instances\n",
      "Examined 284000 instances\n",
      "Examined 285000 instances\n",
      "Examined 286000 instances\n",
      "Examined 287000 instances\n",
      "Examined 288000 instances\n",
      "Examined 289000 instances\n",
      "Examined 290000 instances\n",
      "Examined 291000 instances\n",
      "Examined 292000 instances\n",
      "Examined 293000 instances\n",
      "Examined 294000 instances\n",
      "Examined 295000 instances\n",
      "Examined 296000 instances\n",
      "Examined 297000 instances\n",
      "Examined 298000 instances\n",
      "Examined 299000 instances\n",
      "Examined 300000 instances\n",
      "Examined 301000 instances\n",
      "Examined 302000 instances\n",
      "Examined 303000 instances\n",
      "Examined 304000 instances\n",
      "Examined 305000 instances\n",
      "Examined 306000 instances\n",
      "Examined 307000 instances\n",
      "Examined 308000 instances\n",
      "Examined 309000 instances\n",
      "Examined 310000 instances\n",
      "Examined 311000 instances\n",
      "Examined 312000 instances\n",
      "Examined 313000 instances\n",
      "Examined 314000 instances\n",
      "Examined 315000 instances\n",
      "Examined 316000 instances\n",
      "Examined 317000 instances\n",
      "Examined 318000 instances\n",
      "Examined 319000 instances\n",
      "Examined 320000 instances\n",
      "Examined 321000 instances\n",
      "Examined 322000 instances\n",
      "Examined 323000 instances\n",
      "Examined 324000 instances\n",
      "Examined 325000 instances\n",
      "Examined 326000 instances\n",
      "Examined 327000 instances\n",
      "Examined 328000 instances\n",
      "Examined 329000 instances\n",
      "Examined 330000 instances\n",
      "Examined 331000 instances\n",
      "Examined 332000 instances\n",
      "Examined 333000 instances\n",
      "Examined 334000 instances\n",
      "Examined 335000 instances\n",
      "Examined 336000 instances\n",
      "Examined 337000 instances\n",
      "Examined 338000 instances\n",
      "Examined 339000 instances\n",
      "Examined 340000 instances\n",
      "Examined 341000 instances\n",
      "Examined 342000 instances\n",
      "Examined 343000 instances\n",
      "Examined 344000 instances\n",
      "Examined 345000 instances\n",
      "Examined 346000 instances\n",
      "Examined 347000 instances\n",
      "Examined 348000 instances\n",
      "Examined 349000 instances\n",
      "Examined 350000 instances\n",
      "Examined 351000 instances\n"
     ]
    }
   ],
   "source": [
    "# Compute overall accuracy on training set\n",
    "acc = 0\n",
    "count = 0\n",
    "acc_rand = 0\n",
    "\n",
    "# Compute accuracy grouped by number of assigned variables\n",
    "preds = []\n",
    "for x, pred, y, d in zip(X, predict_val, Y, P):\n",
    "\n",
    "    if count % 1000 == 0:\n",
    "        print(\"Examined {} instances\".format(count))\n",
    "\n",
    "    num_assigned_vars = np.sum(x.astype(np.int8))\n",
    "    pred_label = np.argmax(pred.reshape(-1))\n",
    "    correct_label = np.argmax(y.reshape(-1))\n",
    "\n",
    "    if pred_label == correct_label:\n",
    "        acc += 1\n",
    "        pred_by_num_assigned[num_assigned_vars] += 1\n",
    "\n",
    "    # Create a problem instance with current examples for net prediction\n",
    "    square = np.reshape(x, (DIM, DIM, DIM))\n",
    "    pls = PLSInstance(n=DIM)\n",
    "    pls.square = square.copy()\n",
    "    # assert pls.__check_constraints__(), \"Constraints should be verified before assignment\"\n",
    "\n",
    "    # Make the prediction assignment\n",
    "    assignment = np.argmax(pred)\n",
    "    assignment = np.unravel_index(assignment, shape=(DIM, DIM, DIM))\n",
    "\n",
    "    # Local consistency\n",
    "    local_feas = pls.assign(assignment[0], assignment[1], assignment[2])\n",
    "\n",
    "    '''vals_square = np.argmax(square, axis=2) + np.sum(square, axis=2)\n",
    "    solver = utility.PLSSolver(DIM, square=np.reshape(vals_square, -1))\n",
    "    res = solver.solve()\n",
    "    assert res, \"Constraint solver is wrong because the input comes from a real solution\"'''\n",
    "\n",
    "    # Global consistency\n",
    "    if local_feas:\n",
    "        vals_square = np.argmax(pls.square.copy(), axis=2) + np.sum(pls.square.copy(), axis=2)\n",
    "        solver = PLSSolver(DIM, square=np.reshape(vals_square, -1))\n",
    "        feas = solver.solve()\n",
    "    else:\n",
    "        feas = local_feas\n",
    "\n",
    "    if feas:\n",
    "        feas_by_num_assigned[num_assigned_vars] += 1\n",
    "\n",
    "    # Check random assignment performance if required\n",
    "    if args.rnd_feas:\n",
    "        if not args.use_prop:\n",
    "            d = None\n",
    "        rand_assignment = random_assigner(DIM ** 3, d)\n",
    "        if rand_assignment == correct_label:\n",
    "            acc_rand += 1\n",
    "            rand_pred_by_num_assigned[num_assigned_vars] += 1\n",
    "\n",
    "        # Create a problem instance with current training example for random prediction\n",
    "        square = np.reshape(x, (DIM, DIM, DIM))\n",
    "        pls = PLSInstance(n=DIM)\n",
    "        pls.square = square.copy()\n",
    "        # assert pls.__check_constraints__(), \"Constraints should be verified before assignment\"\n",
    "\n",
    "        # Make the random assignment\n",
    "        rand_assignment = np.unravel_index(rand_assignment, shape=(DIM, DIM, DIM))\n",
    "\n",
    "        local_feas = pls.assign(rand_assignment[0], rand_assignment[1], rand_assignment[2])\n",
    "\n",
    "        # Check global consistency\n",
    "        if local_feas:\n",
    "            vals_square = np.argmax(pls.square.copy(), axis=2) + np.sum(pls.square.copy(), axis=2)\n",
    "            solver = PLSSolver(DIM, square=np.reshape(vals_square, -1))\n",
    "            feas = solver.solve()\n",
    "        else:\n",
    "            feas = local_feas\n",
    "\n",
    "        if feas:\n",
    "            rand_feas_by_num_assigned[num_assigned_vars] += 1\n",
    "\n",
    "    # Increase count of solutions with this number of assignments\n",
    "    tot_by_num_assigned[num_assigned_vars] += 1\n",
    "    count += 1\n",
    "\n",
    "    # Save results checkpoint\n",
    "    if count % 1000 == 0:\n",
    "\n",
    "        feasibility = list((feas_by_num_assigned / (tot_by_num_assigned + 1e-8))[1:])\n",
    "\n",
    "        if not args.use_prop:\n",
    "            filename = \"{}/feasibility_{}.csv\".format(SAVE_PATH, mode)\n",
    "        else:\n",
    "            if args.leave_columns_domains:\n",
    "                filename = \"{}/feasibility_{}_with_row_prop.csv\".format(SAVE_PATH, mode)\n",
    "            else:\n",
    "                filename = \"{}/feasibility_{}_with_full_prop.csv\".format(SAVE_PATH, mode)\n",
    "\n",
    "        with open(filename, \"w\") as epoch_file:\n",
    "            wr = csv.writer(epoch_file)\n",
    "            wr.writerow(feasibility)"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 73,
   "outputs": [],
   "source": [
    "# Check accuracy is correctly computed\n",
    "assert np.sum(pred_by_num_assigned) == acc and np.sum(tot_by_num_assigned) == count, \\\n",
    "    \"acc: {} | acc_vectorized: {} | count: {} | count_vectorized: {}\".format(acc, np.sum(pred_by_num_assigned),\n",
    "                                                                             count, np.sum(tot_by_num_assigned))"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 74,
   "outputs": [],
   "source": [
    "# Make plots\n",
    "\n",
    "accuracy = list((pred_by_num_assigned / (tot_by_num_assigned + 1e-8))[1:])\n",
    "feasibility = list((feas_by_num_assigned / (tot_by_num_assigned + 1e-8))[1:])\n",
    "if args.rnd_feas:\n",
    "    random_feasibility = list((rand_feas_by_num_assigned / (tot_by_num_assigned + 1e-8))[1:])"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 77,
   "outputs": [
    {
     "data": {
      "text/plain": "[0.9912280701464553,\n 0.9804709936803842,\n 0.9721366376410286,\n 0.9631459473882186,\n 0.9541014318199463,\n 0.9395964185474548,\n 0.9253372512342389,\n 0.9132004814753066,\n 0.8969348146153167,\n 0.8884275381718613,\n 0.8655282817491121,\n 0.8473691257185066,\n 0.8312817768252191,\n 0.8003207698465646,\n 0.7753516409902541,\n 0.7368703108243075,\n 0.6994258245417286,\n 0.6499866202827803,\n 0.6063076306286165,\n 0.5496050341403808,\n 0.5040737277941711,\n 0.45188060500541843,\n 0.41613162118724434,\n 0.3863758029973416,\n 0.37553418803368654,\n 0.3684632874142457,\n 0.36673346693337777,\n 0.3660881174894979,\n 0.3763354700849675,\n 0.3803099118349181,\n 0.3920545746383199,\n 0.4037791476810456,\n 0.41264536826572296,\n 0.42616372391596286,\n 0.44569138276493564,\n 0.45412047549024426,\n 0.46924829157112524,\n 0.4875568637938352,\n 0.5188401924097824,\n 0.5476762820505506,\n 0.5759882478624787,\n 0.6101242153057164,\n 0.6486919380664059,\n 0.6881533101036074,\n 0.7433391350907171,\n 0.7875668449187332,\n 0.8427731765951874,\n 0.8699665551827827]"
     },
     "execution_count": 77,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "feasibility"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 75,
   "outputs": [],
   "source": [
    "# Save random assigner results\n",
    "if args.rnd_feas:\n",
    "    RANDOM_SAVE_PATH = \"plots/test-pls-{}-tf-keras/random/\".format(DIM)\n",
    "\n",
    "    if args.use_prop:\n",
    "        if not args.leave_columns_domains:\n",
    "            RANDOM_SAVE_PATH += \"rows-and-columns-prop\"\n",
    "        else:\n",
    "            RANDOM_SAVE_PATH += \"rows-prop\"\n",
    "    else:\n",
    "        RANDOM_SAVE_PATH += \"no-prop\"\n",
    "\n",
    "    try:\n",
    "        os.makedirs(RANDOM_SAVE_PATH)\n",
    "    except:\n",
    "        print(\"Directory {} already exists\".format(RANDOM_SAVE_PATH))\n",
    "\n",
    "    with open(\"{}/random_feasibility.csv\".format(RANDOM_SAVE_PATH, mode), \"w\") as epoch_file:\n",
    "        wr = csv.writer(epoch_file)\n",
    "        wr.writerow(random_feasibility)\n"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}